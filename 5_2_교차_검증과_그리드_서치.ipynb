{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM5wvVR70rqrmklCEL/Rghh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dohyun93/hongong_mldl/blob/main/5_2_%EA%B5%90%EC%B0%A8_%EA%B2%80%EC%A6%9D%EA%B3%BC_%EA%B7%B8%EB%A6%AC%EB%93%9C_%EC%84%9C%EC%B9%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WB3UZ-OljNP",
        "outputId": "60bedc7d-0922-45ba-8689-f1b8632557f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 데이터 shape: (6497, 3)\n",
            "훈련, 검증, 테스트세트 shape: (4157, 3) (1040, 3) (1300, 3)\n"
          ]
        }
      ],
      "source": [
        "# 검증 세트\n",
        "# 테스트세트를 사용하지 않으면 과대적합인지 과소적합인지 알기가 어렵다.\n",
        "# 테스트 세트를 사용하지 않고 측정하는 간단한 방법은 훈련세트를 또 나누는것이다. 이 데이터를 검증 세트라고 한다.\n",
        "\n",
        "# 즉 전체 데이터가 100이라고 했을 때, 훈련세트를 60, 검증세트를 20, 테스트세트를 20으로 구성한다.\n",
        "# (데이터가 많다면 적은비율로 해도 데이터 대표성을 띄기 때문에 괜찮다.)\n",
        "\n",
        "import pandas as pd\n",
        "wine = pd.read_csv('https://bit.ly/wine_csv_data')\n",
        "data = wine[['alcohol', 'sugar', 'pH']]\n",
        "target = wine['class'].to_numpy()\n",
        "\n",
        "print(\"전체 데이터 shape:\", data.shape)\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_input, test_input, train_target, test_target = train_test_split(data, target, test_size=0.2, random_state=42)\n",
        "#train_input, train_target 을 훈련세트와 검증 세트로 만든다.\n",
        "sub_input, val_input, sub_target, val_target = train_test_split(train_input, train_target, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"훈련, 검증, 테스트세트 shape:\", sub_input.shape, val_input.shape, test_input.shape)\n",
        "# sub_input: 훈련세트\n",
        "# val_input: 검증세트"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " from sklearn.tree import DecisionTreeClassifier\n",
        " dt = DecisionTreeClassifier(random_state=42)\n",
        " dt.fit(sub_input, sub_target)\n",
        " print(\"1. 훈련세트 스코어: \", dt.score(sub_input, sub_target))\n",
        " print(\"2. 검증세트 스코어: \", dt.score(val_input, val_target))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RD92Wv98mFPT",
        "outputId": "ca41b859-4a28-4c78-d3f7-ff7d70013b00"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. 훈련세트 스코어:  0.9971133028626413\n",
            "2. 검증세트 스코어:  0.864423076923077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 검증 세트를 만드느라 훈련세트가 줄었다.\n",
        "# 보통 많은 데이터를 훈련에 사용할 수록 좋은 모델이 만들어지는데 그렇다고 검증세트를 너무 조금 떼어내면 검증점수가 들쭉날쭉하고 불안정할 것이다.\n",
        "# 이럴 때 '교차 검증' (cross-validation) 을 이용하면 안정적인 검증 점수를 얻고 훈련에 더 많은 데이터를 사용할 수 있다.\n",
        "\n",
        "# K-fold 교차 검증"
      ],
      "metadata": {
        "id": "EcsWKKUupBRR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 교차 검증\n",
        "\n",
        "교차 검증은 훈련세트를 훈련세트와 검증세트로 나눈 뒤 이를 번갈아 교차해가면서 훈련시키는 방법이다.\n",
        "\n",
        "훈련 세트를 세 부분으로 나누어 훈련/검증 세트로 나누고 이를 번갈아 가며 훈련시킨 뒤 검증점수를 평균내어 학습된 성능을 확인한다."
      ],
      "metadata": {
        "id": "pJwvY8HPFwst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 보통 5-fold, 10-fold 교차 검증을 많이 사용한다.\n",
        "# 여기서는 예시로 3-Fold 교차검증을 살펴본다.\n",
        "\n",
        "# 사이킷런에는 cross_validate()라는 교차 검증 함수가 있다. \n",
        "# 평가할 모델 객체와 훈련/검증 세트로 나누기 전의 훈련세트를 통째로 전달한다.\n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "scores = cross_validate(dt, train_input, train_target)\n",
        "print(scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTi6RrlNGO_O",
        "outputId": "c13429d5-86d6-4f95-beb1-309e1e377aa0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fit_time': array([0.01492095, 0.00879169, 0.00952792, 0.00874639, 0.00863361]), 'score_time': array([0.00230408, 0.00189447, 0.0019834 , 0.00185513, 0.00178981]), 'test_score': array([0.86923077, 0.84615385, 0.87680462, 0.84889317, 0.83541867])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cross_validate 함수는 기본적으로 5-fold 교차검증을 수행한다.\n",
        "# 'cv' 매개변수로 이를 조절할 수 있다.\n",
        "\n",
        "# fit_time: 훈련세트로 모델을 훈련하는데 걸린 시간\n",
        "# score_time: 검증세트로 모델을 평가하는데 걸린 시간\n",
        "# test_score: 교차검증에서 k-fold의 각 경우에 대한 검증세트의 점수\n",
        "\n",
        "# 따라서 test_score 점수의 평균이 곧 이 k-fold 교차검증의 점수이다.\n",
        "import numpy as np\n",
        "print(np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuNzbmSsHSEq",
        "outputId": "5ff3c678-c406-4670-b38a-24fb5706bf56"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.855300214703487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 유의할 점은 교차검증 함수 cross_validate() 는 훈련세트를 섞어 폴드를 나누지 않는다.\n",
        "\n",
        "> 앞서 train_test_split 으로 훈련세트를 섞었기 때문에 여기서는 따로 섞을 필요가 없지만, 만약 앞서 그런 단계가 없었을 경우 '분할기(splitter)' 를 지정해야 한다.\n",
        "\n",
        "> 사이킷런에서 분할기는 교차검증에서 폴드를 어떻게 나눌지 결정해준다. cross_validate() 는 기본적으로 회귀 모델일 경우 ```KFold``` 분할기를 사용하고, 분류 모델일 경우 ```StratifiedKFold``` 를 사용한다. (stratify: 층을 이루다)"
      ],
      "metadata": {
        "id": "L6D7_Pj4H-7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 분류 모델이기 때문에 위 셀과 점수가 동일하다는 걸 확인할 수 있다.\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "scores = cross_validate(dt, train_input, train_target, cv=StratifiedKFold())\n",
        "print(np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3eEdNb5HR9-",
        "outputId": "4ce186b1-4b00-4b5b-a08b-b8062e5ffeaa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.855300214703487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 만약 10-fold 교차 검증을 하려면 어떻게 할까?\n",
        "splitter = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "scores = cross_validate(dt, train_input, train_target, cv=splitter)\n",
        "print(\"10fold cross-validate scores: \", np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaDzexGNJkj6",
        "outputId": "7cdb2479-d440-4c6b-8b1d-326986309c61"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10fold cross-validate scores:  0.8574181117533719\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 하이퍼파라미터 튜닝\n",
        "\n",
        "머신러닝 모델이 학습하는 파라미터를 ```모델 파라미터``` 라고 부른다고 했다.\n",
        "\n",
        "하지만 머신러닝 개발자가 직접 조절해야 하는 파라미터를 ```하이퍼 파라미터``` 라고 부른다고 했는데, 이 값이 다수일 경우 한 파라미터를 고정하고 다른 파라미터를 조절하는게 아니라, ```동시에 하이퍼파라미터를 바꿔가며 최적의 값을 찾아야 한다.```\n",
        "\n",
        "```GridSearchCV``` 는 교차검증과 하이퍼파라미터 최적 값 찾기를 동시에 수행해준다. 별도로 cross_validate 를 호출할 필요가 없다."
      ],
      "metadata": {
        "id": "vEiMtOwIKxo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. GridSearchCV import\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 탐색할 하이퍼파라미터\n",
        "params = {'min_impurity_decrease': [0.0001, 0.0002, 0.0003, 0.0004, 0.0005]}\n",
        "\n",
        "# 그리드 서치 교차검증 객체 생성.\n",
        "# n_jobs : 투입할 CPU 코어 수 (1이 디폴트)\n",
        "gs = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1)\n",
        "gs.fit(train_input, train_target)"
      ],
      "metadata": {
        "id": "g1rDGHV0NkoS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71b7d7a8-e3b7-416c-d57e-c227f683b708"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=DecisionTreeClassifier(random_state=42), n_jobs=-1,\n",
              "             param_grid={'min_impurity_decrease': [0.0001, 0.0002, 0.0003,\n",
              "                                                   0.0004, 0.0005]})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GridSearchCV의 디폴트 cv값은 5다.\n",
        "# 따라서 위 하이퍼파라미터 딕셔너리로 각 하이퍼파라미터마다 5-fold 교차검증을 수행하므로 5 x 5 = 25 개의 모델을 훈련한다.\n",
        "\n",
        "# (중요)\n",
        "# 교차 검증에서 최적의 파라미터를 찾으면 '전체 훈련 세트'로 모델을 다시 만들어야 한다고 했다.\n",
        "# 편리하게 사이킷런의 그리드 서치는 훈련이 끝나면 전체 훈련한 모델 중 검증 점수가 가장 높은 모델의 매개변수\n",
        "# 조합으로 전체 훈련 세트에서 자동으로 다시 모델을 훈련한다.\n",
        "\n",
        "# 이 '최적' 모델은 gs 객체의 'best_estimator_' 속성에 저장되어 있다.\n",
        "\n",
        "# 1. 결정트리 모델 객체를 최적의 모델로 교체\n",
        "dt = gs.best_estimator_\n",
        "print(dt.score(train_input, train_target))\n",
        "\n",
        "# 2. 최적 모델의 모델 파라미터는 'best_params_'에 있다.\n",
        "print(gs.best_params_)\n",
        "\n",
        "# 3. '각 하이퍼파라미터에 대해' 교차검증을 수행한 각 '교차 검증의 평균 점수'는 'cv_results_' 속성의 'mean_test_score' 키에 있다.\n",
        "# 5번의 교차 검증으로 얻은 점수를 확인해보자.\n",
        "print(gs.cv_results_['mean_test_score'])\n",
        "\n",
        "# 4. np.argmax 는 가장 큰 값의 인덱스를 추출할 수 있다.\n",
        "best_index = np.argmax(gs.cv_results_['mean_test_score'])\n",
        "# gs.cv_results_ 의 'params'에서 그 인덱스 값을 조회해보면 gs.best_params_, 즉 최적의 모델 파라미터 값과 동일한 걸 알 수 있다.\n",
        "print(gs.cv_results_['params'][best_index])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-bh27dMHX-9",
        "outputId": "e1d0f9c4-f364-4d7b-8412-02ce13a86cc9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9615162593804117\n",
            "{'min_impurity_decrease': 0.0001}\n",
            "[0.86819297 0.86453617 0.86492226 0.86780891 0.86761605]\n",
            "{'min_impurity_decrease': 0.0001}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xeLchW1UJkOe"
      }
    }
  ]
}