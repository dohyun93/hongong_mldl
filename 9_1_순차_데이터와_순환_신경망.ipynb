{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOY0T09nb+vS6FjEzd6CJC+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dohyun93/hongong_mldl/blob/main/9_1_%EC%88%9C%EC%B0%A8_%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%99%80_%EC%88%9C%ED%99%98_%EC%8B%A0%EA%B2%BD%EB%A7%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 순차 데이터 (Sequential Data)\n",
        "\n",
        "> ```순차 데이터(sequential data)``` 는 ```1) 텍스트``` 또는 ```2) 시계열 데이터 (Time series data)``` 와 같이 ```순서에 의미가 있는 데이터```를 말한다.\n",
        "\n",
        "> \n",
        "\n",
        "# 2. 순환 신경망 (RNN, Recurrent Neural Network)\n",
        "\n",
        "> 기존에 완전연결 신경망이나 합성곱 신경망처럼 입력이 출력까지 신경망의 흐름이 진행되는 신경망을 ```피드포워드 신경망(FFNN)```이라고 부른다. \n",
        "\n",
        "> ```텍스트나 시계열 데이터가 학습되려면 먼저 등장한 데이터에 대한 기억이 필요하기 때문에```, 피드포워드 신경망처럼 샘플이 정방향 계산을 수행하고 버려지는 것이 아니라, ```이전 데이터가 신경망 층에 순환될 필요가 있다.```\n",
        "\n",
        "> 2nd 순차 데이터를 학습하기 위해 1st 순차 데이터를 재사용 하기 위해서는 FFNN 처럼 차례대로 순차 데이터를 뒤로만 전달하지 않고, 1st 순차 데이터의 출력이 포함된 것을 다시 신경망에 전달해야 한다.\n"
      ],
      "metadata": {
        "id": "dv3-SrRpyK5J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. RNN 구조\n",
        "\n",
        "> RNN 은 FNN와 구조적으로 매우 유사하나, 단지 차이가 있다면 출력이 다시 다음 샘플입력에 포함된다는 것이다.\n",
        "\n",
        "> 즉, 첫 번째 샘플데이터 A가 입력되고 난 뒤, 활성화함수를 거쳐 나온 출력 $O_A$ 가 있다면 다음 샘플 데이터 B가 입력될 때 $O_A$ 가 같이 입력된다.\n",
        "\n",
        "> 따라서, 신경망은 A와 B에 대한 데이터를 훈련하여 $O_B$ 를 출력하고, 여기에는 A, B에 대한 정보가 포함되어 있다. 이후 C 데이터를 훈련할 때 역시 $O_B$ 를 같이 입력하고, 이 과정을 반복한다. 이렇게, $O_C$ 에 A, B에 대한 정보가 포함되어 있는 것을 보고 RNN에서는 ```이전 샘플에 대한 기억을 가지고 있다``` 고 말할 수 있다.\n",
        "\n",
        "> 이렇게 샘플을 처리하는 한 단계를 ```타임스텝 (Timestep)``` 이라고 한다.\n",
        "\n",
        "> RNN에서는 ```층``` 을 ```셀(cell)``` 이라고 부른다.\n",
        "\n",
        "> FNN와 달리 각 층마다 존재하는 뉴런을 모두 표시하지만, ```RNN은 뉴런을 모두 표시하지 않고, 하나의 셀로 층을 표현한다.```\n",
        "\n",
        "> RNN의 출력을 ```은닉 상태(hidden state)``` 라고 한다.\n",
        "\n",
        "> 일반적으로 ```RNN 은닉층의 활성화 함수는 하이퍼볼릭 탄젠트 함수(hyperbolic tangent) 인 tanh 가 많이 사용된다.```\n",
        "\n",
        "> CNN과 같이 피드포워드 신경망에서 뉴런은 입력과 가중치를 곱한다. RNN도 동일하나, RNN의 뉴런은 가중치가 하나 더 있다. 바로 ```이전 타임스텝의 은닉상태에 곱해지는 가중치``` 이다.\n",
        "\n",
        "> RNN에는 이렇게 두 종류의 가중치가 존재한다. $w_x$ (입력에 곱해지는 가중치) 와, $w_h$ (은닉상태에 곱해지는 가중치) 가 바로 그것이다.\n",
        "\n",
        "> 즉, 아래처럼 표시할 수 있다. (A, B, C 가 순차적으로 입력되는 순차데이터이며, 함수 C는 RNN을 의미)\n",
        "\n",
        "##timestep 1\n",
        "\n",
        "$O_A = h_1 = tanh(C(h_0, w_h, A, w_x) + b)$ \n",
        "\n",
        "$(h_0은 모두 0으로 초기화)$\n",
        "\n",
        "\n",
        "##timestep 2\n",
        "\n",
        "$O_B = h_2 = tanh(C(h_1, w_h, B, w_x) + b)$\n",
        "\n",
        "\n",
        "> 여기에서 알 수 있는 점은 모든 타임스텝에서 사용되는 은닉상태의 가중치 $w_b$ 가 하나라는 점이다. $w_b$ 는 타임스텝에 따라 변화되는 뉴런의 출력을 학습한다. 이 능력이 순차 데이터를 학습하는데 필요한 것이다."
      ],
      "metadata": {
        "id": "xdwCfxLrSJnA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. 셀의 가중치와 입출력\n",
        "\n",
        "> 입력층의 뉴런이 4개, 순환층의 뉴런이 3개라고 가정했을 때, 모든 모델파라미터의 개수는 어떻게 알 수 있을까? 입력층과 순환층 사이 가중치인 $w_x = 4 \\times 3 = 12$ 이며, $w_h = 3 \\times 3 = 9$ 이며, $b = 3$ 개 이므로 총 24개의 모델 파라미터가 있다.\n",
        "\n",
        "> $w_h$ 계산한 방법은 순환층의 각 뉴런의 출력이 해당층의 모든 뉴런으로 전달되기 때문에, 이에 곱해질 가중치가 필요하다. 즉, $n_1$ 뉴런의 출력이 $n_1$, $n_2$, $n_3$ 으로 전달되고, 다른 뉴런들도 동일하기 때문에, $(순환층의뉴런수)^2$ 가 곧 $w_b$ 의 수가 된다.\n",
        "\n",
        "> 절편 $b$의 경우 순환층의 뉴런 개수와 동일하다.\n",
        "\n",
        "> ```순환층은 일반적으로 샘플마다 2개의 차원```을 갖는다.\n",
        "\n",
        "> 보통 ```하나의 샘플을 시퀀스 (sequence)```라고 부른다. 이 시퀀스에는 여러 아이템이 들어있다.\n",
        "\n",
        "> ```시퀀스의 길이 = 타임스텝 길이```\n",
        "\n",
        "> 샘플이 \"I am a boy\" 라고 해보자. 이 샘플은 4개의 단어로 이루어져있고, 각 단어를 3개의 어떤 숫자로 표현한다고 해보자. 그러면 이 샘플은 (1, 4, 3)이라는 타임스텝 크기로 나타낼 수 있다. (맨 앞 1은 미니배치 크기)\n",
        "\n",
        "> 여기서 4는 ```시퀀스 길이(여기서는 단어개수)```이며, 3은 ```단어 표현```이다.\n",
        "\n",
        "> 순환층이 1개만 존재하는 경우, 순환층은 ```마지막 타임스텝의 은닉 상태``` 만 출력으로 내보낸다. 그 전까지 타임스텝의 은닉상태는 다음 타임스텝의 입력에 같이 셀로 전달된다.\n",
        "\n",
        "> 순환층을 셀로 표현한다고 한 것을 떠올려보자. 이 셀은 중첩될 수 있다.\n",
        "\n",
        "> 순환층이 중첩되어 있는 경우, ```순환층2만 '마지막 타임스텝의' 은닉 상태를 출력하여 모든 시퀀스 길이를 읽고나서 정보를 마지막 은닉 상태에 압축해서 전달```하고, ```순환층1은 '모든 타입스텝의' 은닉 상태를 다음 순환층으로 전달```한다.\n",
        "\n",
        "> 순환신경망의 입력: 1) ```시퀀스길이=타임스텝길이``` 2)```표현(=특성)``` 이며, ```위에서는 각각 시퀀스의 길이인 단어 개수와, 단어 표현이 예시```로 사용되었다."
      ],
      "metadata": {
        "id": "Ef6K3yiAZ27q"
      }
    }
  ]
}